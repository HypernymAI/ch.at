deployments:
  # ============================================
  # WORKING GPT Models - Channel 1 (-1 suffix)
  # ============================================
  
  gpt-35-turbo-openai:
    model_id: "gpt-3.5-turbo"
    provider: "oneapi"
    provider_model_id: "gpt-3.5-turbo"
    priority: 1
    weight: 50
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 30s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      gateway: "oneapi"
      backend: "openai"
      channel: "1"

  gpt-4-turbo-openai:
    model_id: "gpt-4-turbo"
    provider: "oneapi"
    provider_model_id: "gpt-4-turbo"
    priority: 1
    weight: 50
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 60s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      gateway: "oneapi"
      backend: "openai"
      channel: "1"

  # ============================================
  # WORKING Claude Models - Channel 2 (-2 suffix)
  # ============================================
  
  claude-3-opus-anthropic:
    model_id: "claude-3-opus"
    provider: "oneapi"
    provider_model_id: "claude-3-opus-20240229"
    priority: 1
    weight: 50
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 60s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      gateway: "oneapi"
      backend: "anthropic"
      channel: "2"

  claude-3-haiku-anthropic:
    model_id: "claude-3-haiku"
    provider: "oneapi"
    provider_model_id: "claude-3-haiku-20240307"
    priority: 1
    weight: 50
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 30s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      gateway: "oneapi"
      backend: "anthropic"
      channel: "2"

  # ============================================
  # WORKING Llama Models - Channel 4 (-4 suffix, Azure)
  # ============================================
  
  llama-8b-azure:
    model_id: "llama-8b"
    provider: "oneapi"
    provider_model_id: "Meta-Llama-31-8B-Instruct-2"
    priority: 1
    weight: 50
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 30s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      gateway: "oneapi"
      backend: "azure"
      channel: "4"

  # ============================================
  # WORKING Llama Models - Channel 10 (no suffix, AWS Bedrock)
  # ============================================
  
  llama-3-8b-bedrock:
    model_id: "llama-8b"
    provider: "oneapi"
    provider_model_id: "llama-3-8b"
    priority: 2
    weight: 40
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 30s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      gateway: "oneapi"
      backend: "bedrock"
      channel: "10"

  llama-3-70b-bedrock:
    model_id: "llama-70b"
    provider: "oneapi"
    provider_model_id: "llama-3-70b"
    priority: 1
    weight: 50
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 60s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      gateway: "oneapi"
      backend: "bedrock"
      channel: "10"

  # ============================================
  # WORKING - Claude on AWS (no suffix) - but commented due to billing
  # ============================================
  
  # claude-35-sonnet-bedrock:
  #   model_id: "claude-3-sonnet"
  #   provider: "oneapi"
  #   provider_model_id: "claude-3-5-sonnet-20240620"
  #   priority: 2
  #   weight: 30
  #   endpoint:
  #     base_url: "${ONE_API_URL:-http://localhost:3000}"
  #     timeout: 60s
  #     max_retries: 2
  #     use_openai_format: true
  #     auth:
  #       type: "api_key"
  #   tags:
  #     gateway: "oneapi"
  #     backend: "bedrock"
  #     channel: "10"

# Model definitions
models:
  gpt-3.5-turbo:
    name: "GPT-3.5 Turbo"
    capabilities:
      - "chat"
      - "completion"
    max_tokens: 4096
    cost:
      input: 0.0005
      output: 0.0015

  gpt-4-turbo:
    name: "GPT-4 Turbo"
    capabilities:
      - "chat"
      - "completion"
    max_tokens: 128000
    cost:
      input: 0.01
      output: 0.03

  claude-3-opus:
    name: "Claude 3 Opus"
    capabilities:
      - "chat"
      - "completion"
    max_tokens: 200000
    cost:
      input: 0.015
      output: 0.075

  claude-3-haiku:
    name: "Claude 3 Haiku"
    capabilities:
      - "chat"
      - "completion"
    max_tokens: 200000
    cost:
      input: 0.00025
      output: 0.00125

  llama-8b:
    name: "Llama 3 8B"
    capabilities:
      - "chat"
      - "completion"
    max_tokens: 8192
    cost:
      input: 0.0002
      output: 0.0002

  llama-70b:
    name: "Llama 3 70B"
    capabilities:
      - "chat"
      - "completion"
    max_tokens: 8192
    cost:
      input: 0.0007
      output: 0.0007

# Routing strategies
routing:
  default_strategy: "priority"
  fallback_enabled: true
  health_check:
    enabled: true
    interval: 30s
    timeout: 5s
    unhealthy_threshold: 3
    healthy_threshold: 2