# Strategic Multi-Provider LLM Deployments
# Horizontal Capacity: Multiple channels for rate limit distribution
# Vertical Depth: Three tiers - Fast, Balanced, Frontier

deployments:
  # ============================================
  # FAST TIER - Quick, cheap responses
  # ============================================
  
  # Claude Haiku - Ultra fast Claude
  claude-haiku-ch2:
    model_id: "claude-haiku"
    provider: "oneapi"
    provider_model_id: "claude-3-5-haiku-20241022"
    priority: 1
    weight: 40
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 15s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "fast"
      channel: "2"
      cost_tier: "low"

  # GPT-4.1 Nano - Tiny OpenAI
  gpt-41-nano-ch8:
    model_id: "gpt-nano"
    provider: "oneapi"
    provider_model_id: "gpt-4.1-nano"
    priority: 1
    weight: 30
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 15s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "fast"
      channel: "8"
      cost_tier: "low"

  # Gemini 1.5 Flash - Google fast
  gemini-flash-ch3:
    model_id: "gemini-flash"
    provider: "oneapi"
    provider_model_id: "gemini-1.5-flash"
    priority: 1
    weight: 30
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 15s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "fast"
      channel: "3"
      cost_tier: "low"

  # Llama 3 8B - Small open model (AWS)
  llama-8b-ch10:
    model_id: "llama-8b"
    provider: "oneapi"
    provider_model_id: "llama-3-8b"
    priority: 2
    weight: 20
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 15s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "fast"
      channel: "10"
      cost_tier: "low"

  # Llama 3.1 8B - Newer small (Azure)
  llama-31-8b-ch4:
    model_id: "llama-8b"
    provider: "oneapi"
    provider_model_id: "Meta-Llama-31-8B-Instruct-2"
    priority: 3
    weight: 20
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 15s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "fast"
      channel: "4"
      cost_tier: "low"

  # ============================================
  # BALANCED TIER - Good performance/cost ratio
  # ============================================
  
  # Claude 3.7 Sonnet - Latest balanced Claude
  claude-37-sonnet-ch2:
    model_id: "claude-sonnet"
    provider: "oneapi"
    provider_model_id: "claude-3-7-sonnet-20250219"
    priority: 1
    weight: 35
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 30s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "balanced"
      channel: "2"
      cost_tier: "medium"

  # Claude 3.5 Sonnet - Proven balanced (AWS)
  claude-35-sonnet-ch10:
    model_id: "claude-sonnet"
    provider: "oneapi"
    provider_model_id: "claude-3-5-sonnet-20240620"
    priority: 2
    weight: 25
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 30s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "balanced"
      channel: "10"
      cost_tier: "medium"

  # GPT-4.1 Mini - Balanced OpenAI
  gpt-41-mini-ch8:
    model_id: "gpt-mini"
    provider: "oneapi"
    provider_model_id: "gpt-4.1-mini"
    priority: 1
    weight: 30
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 30s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "balanced"
      channel: "8"
      cost_tier: "medium"

  # Llama 3 70B - Large open model (AWS)
  llama-70b-ch10:
    model_id: "llama-70b"
    provider: "oneapi"
    provider_model_id: "llama-3-70b"
    priority: 1
    weight: 25
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 45s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "balanced"
      channel: "10"
      cost_tier: "medium"

  # Llama 4 Scout - Efficient 16 experts
  llama-scout-ch10:
    model_id: "llama-scout"
    provider: "oneapi"
    provider_model_id: "llama-4-scout-17b"
    priority: 2
    weight: 20
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 30s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "balanced"
      channel: "10"
      cost_tier: "medium"

  # Llama 4 Scout - Azure backup
  llama-scout-ch4:
    model_id: "llama-scout"
    provider: "oneapi"
    provider_model_id: "Llama-4-Scout-17B-16E-Instruct"
    priority: 3
    weight: 15
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 30s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "balanced"
      channel: "4"
      cost_tier: "medium"

  # Gemini 2.5 Flash - Newer fast/balanced
  gemini-25-flash-ch3:
    model_id: "gemini-balanced"
    provider: "oneapi"
    provider_model_id: "gemini-2.5-flash"
    priority: 2
    weight: 20
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 30s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "balanced"
      channel: "3"
      cost_tier: "medium"

  # ============================================
  # FRONTIER TIER - Maximum capability
  # ============================================
  
  # Claude Opus 4.1 - Latest frontier Claude  
  claude-opus-41-ch2:
    model_id: "claude-4-1-opus"
    provider: "oneapi"
    provider_model_id: "claude-opus-4-1-20250805"
    priority: 1
    weight: 30
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 60s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "frontier"
      channel: "2"
      cost_tier: "high"

  # Claude Opus 4 - Frontier Claude
  claude-opus-4-ch2:
    model_id: "claude-opus"
    provider: "oneapi"
    provider_model_id: "claude-opus-4-20250514"
    priority: 2
    weight: 25
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 60s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "frontier"
      channel: "2"
      cost_tier: "high"

  # GPT-5 Chat - Frontier OpenAI
  gpt-5-chat-ch8:
    model_id: "gpt-5"
    provider: "oneapi"
    provider_model_id: "gpt-5-chat"
    priority: 1
    weight: 30
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 60s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "frontier"
      channel: "8"
      cost_tier: "high"

  # GPT-4.1 Full - Advanced OpenAI
  gpt-41-full-ch8:
    model_id: "gpt-41"
    provider: "oneapi"
    provider_model_id: "gpt-4.1"
    priority: 2
    weight: 25
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 60s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "frontier"
      channel: "8"
      cost_tier: "high"

  # Llama 405B - Massive open model
  llama-405b-ch4:
    model_id: "llama-405b"
    provider: "oneapi"
    provider_model_id: "Meta-Llama-31-405B-Instruct"
    priority: 2
    weight: 20
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 90s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "frontier"
      channel: "4"
      cost_tier: "high"

  # Llama 4 Maverick - Powerful 128 experts (AWS)
  llama-maverick-ch10:
    model_id: "llama-maverick"
    provider: "oneapi"
    provider_model_id: "llama-4-maverick-17b"
    priority: 3
    weight: 20
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 45s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "frontier"
      channel: "10"
      cost_tier: "high"

  # Llama 4 Maverick - Azure backup
  llama-maverick-ch4:
    model_id: "llama-maverick"
    provider: "oneapi"
    provider_model_id: "Llama-4-Maverick-17B-128E-Instruct-FP8"
    priority: 4
    weight: 15
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 45s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "frontier"
      channel: "4"
      cost_tier: "high"

  # Gemini 2.5 Pro - Google frontier
  gemini-25-pro-ch3:
    model_id: "gemini-pro"
    provider: "oneapi"
    provider_model_id: "gemini-2.5-pro"
    priority: 2
    weight: 25
    endpoint:
      base_url: "${ONE_API_URL:-http://localhost:3000}"
      timeout: 60s
      max_retries: 2
      use_openai_format: true
      auth:
        type: "api_key"
    tags:
      tier: "frontier"
      channel: "3"
      cost_tier: "high"

# ============================================
# Model Registry
# ============================================
models:
  # Fast Tier
  claude-haiku:
    name: "Claude 3.5 Haiku"
    capabilities: ["chat", "completion"]
    max_tokens: 200000
    cost:
      input: 0.00025
      output: 0.00125

  gpt-nano:
    name: "GPT-4.1 Nano"
    capabilities: ["chat", "completion"]
    max_tokens: 16384
    cost:
      input: 0.0001
      output: 0.0003

  gemini-flash:
    name: "Gemini 1.5 Flash"
    capabilities: ["chat", "completion", "vision"]
    max_tokens: 128000
    cost:
      input: 0.000075
      output: 0.00015

  llama-8b:
    name: "Llama 3 8B"
    capabilities: ["chat", "completion"]
    max_tokens: 8192
    cost:
      input: 0.0002
      output: 0.0002

  # Balanced Tier
  claude-sonnet:
    name: "Claude 3.7 Sonnet"
    capabilities: ["chat", "completion", "vision"]
    max_tokens: 200000
    cost:
      input: 0.003
      output: 0.015

  gpt-mini:
    name: "GPT-4.1 Mini"
    capabilities: ["chat", "completion"]
    max_tokens: 32768
    cost:
      input: 0.0005
      output: 0.0015

  llama-70b:
    name: "Llama 3 70B"
    capabilities: ["chat", "completion"]
    max_tokens: 8192
    cost:
      input: 0.0007
      output: 0.0007

  llama-scout:
    name: "Llama 4 Scout"
    capabilities: ["chat", "completion"]
    max_tokens: 16384
    cost:
      input: 0.0008
      output: 0.0008

  gemini-balanced:
    name: "Gemini 2.5 Flash"
    capabilities: ["chat", "completion", "vision"]
    max_tokens: 128000
    cost:
      input: 0.00015
      output: 0.0003

  # Frontier Tier
  claude-opus:
    name: "Claude Opus 4.1"
    capabilities: ["chat", "completion", "vision", "analysis"]
    max_tokens: 200000
    cost:
      input: 0.015
      output: 0.075

  gpt-5:
    name: "GPT-5 Chat"
    capabilities: ["chat", "completion", "reasoning"]
    max_tokens: 128000
    cost:
      input: 0.02
      output: 0.06

  gpt-41:
    name: "GPT-4.1"
    capabilities: ["chat", "completion", "vision"]
    max_tokens: 128000
    cost:
      input: 0.01
      output: 0.03

  llama-405b:
    name: "Llama 3.1 405B"
    capabilities: ["chat", "completion"]
    max_tokens: 32768
    cost:
      input: 0.003
      output: 0.003

  llama-maverick:
    name: "Llama 4 Maverick"
    capabilities: ["chat", "completion", "reasoning"]
    max_tokens: 32768
    cost:
      input: 0.002
      output: 0.002

  gemini-pro:
    name: "Gemini 2.5 Pro"
    capabilities: ["chat", "completion", "vision", "analysis"]
    max_tokens: 128000
    cost:
      input: 0.00035
      output: 0.00105

# ============================================
# Routing Configuration
# ============================================
routing:
  default_strategy: "tier_based"
  
  strategies:
    # Route by tier first, then by priority/weight
    tier_based:
      type: "custom"
      rules:
        - match: {tier: "fast"}
          strategy: "weighted"
        - match: {tier: "balanced"}
          strategy: "priority"
        - match: {tier: "frontier"}
          strategy: "least_cost"
    
    # For cost optimization
    cost_optimized:
      type: "custom"
      rules:
        - match: {cost_tier: "low"}
          strategy: "round_robin"
        - match: {cost_tier: "medium"}
          strategy: "weighted"
        - match: {cost_tier: "high"}
          strategy: "least_cost"
    
    # For maximum reliability
    high_availability:
      type: "custom"
      rules:
        - strategy: "health_weighted"
          fallback_chain:
            - {tier: "balanced"}
            - {tier: "frontier"}
            - {tier: "fast"}
  
  # Fallback configuration
  fallback:
    enabled: true
    strategy: "tier_cascade"  # Fall through tiers
    max_attempts: 3
  
  # Health checking
  health_check:
    enabled: true
    interval: 30s
    timeout: 5s
    unhealthy_threshold: 3
    healthy_threshold: 2
    
  # Circuit breaker
  circuit_breaker:
    enabled: true
    failure_threshold: 5
    recovery_timeout: 30s
    half_open_requests: 2